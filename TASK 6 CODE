1)SALES DATA

%pip install seaborn:
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error
from math import sqrt
# Load dataset (Replace 'sales_data.csv' with your actual file)
df = pd.read_csv('sales.csv', parse_dates=['Date'], index_col='Date')
df = df.asfreq('D')  # Ensuring date frequency is set

df['Sales'] = df['Sales'].ffill()  # Forward fill missing values

# Visualizing sales trend
plt.figure(figsize=(12,6))
plt.plot(df['Sales'], label='Sales Data', color='blue')
plt.title('Sales Trend Over Time')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.show()

# Check stationarity using Augmented Dickey-Fuller (ADF) test
def adf_test(series):
    result = adfuller(series.dropna())
    print(f'ADF Statistic: {result[0]}')
    print(f'p-value: {result[1]}')
    if result[1] <= 0.05:
        print("Data is stationary")
    else:
        print("Data is non-stationary")

adf_test(df['Sales'])

# Differencing if needed
df['Sales_diff'] = df['Sales'].diff()

# Recheck stationarity
adf_test(df['Sales_diff'])

# Train ARIMA model
p, d, q = 1, 1, 1  # Adjust based on ACF/PACF plots
test_size = int(len(df) * 0.2)
train, test = df['Sales'][:-test_size], df['Sales'][-test_size:]

model = ARIMA(train, order=(p, d, q))
model_fit = model.fit()
print(model_fit.summary())

# Forecast future sales
forecast = model_fit.forecast(steps=len(test))

# Evaluate Model
rmse = sqrt(mean_squared_error(test, forecast))
print(f'RMSE: {rmse}')

# Plot actual vs predicted
plt.figure(figsize=(12,6))
plt.plot(test.index, test, label='Actual Sales', color='blue')
plt.plot(test.index, forecast, label='Predicted Sales', color='red', linestyle='dashed')
plt.title('Actual vs Predicted Sales')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.show()

2)HEART DISEASE:

%pip install seaborn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
# Load dataset
df = pd.read_csv('heart-disease.csv')

# ✅ Fix Column Names (Remove Spaces)
df.columns = df.columns.str.strip()

# ✅ Check if 'Blood Pressure' exists
print(df.columns)


# Convert categorical data (Gender)
df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})

# Ensure target variable is numeric
df['Heart Disease'] = df['Heart Disease'].astype(int)

# Define features and target variable
X = df.drop(columns=['Heart Disease'])
y = df['Heart Disease']

# Split dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize numerical features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

print(f"\nModel Accuracy: {accuracy:.4f}")
print("\nConfusion Matrix:")
print(conf_matrix)
print("\nClassification Report:")
print(classification_rep)

# Plot confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=['No Disease', 'Disease'], yticklabels=['No Disease', 'Disease'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()
